import base64
import io
from fastapi import Body, HTTPException
from main import app, client
from endpoints.audio_isolation import audio_isolation


@app.post("/stt")
async def speech_to_text(data: dict = Body(...)):
    print("[/stt] ğŸ¤ Ä°stek alÄ±ndÄ±.")

    base64_audio = data.get("base64")
    if not base64_audio:
        print("[/stt] âš ï¸ Ses verisi (base64) bulunamadÄ±.")
        return {"error": "Ses verisi eksik"}

    try:
        # (Ä°steÄŸe baÄŸlÄ±) Lokal gÃ¼rÃ¼ltÃ¼ azaltma endpointâ€™imiz
        print("[/stt] ğŸ”„ Audio Isolation Ã§aÄŸrÄ±lÄ±yor...")
        try:
            isolate_resp = await audio_isolation({"base64": base64_audio})
            if isinstance(isolate_resp, dict) and isolate_resp.get("audio_base64"):
                base64_audio = isolate_resp["audio_base64"]
                print("[/stt] ğŸ› GÃ¼rÃ¼ltÃ¼sÃ¼z sesle devam ediliyor.")
            else:
                print("[/stt] âš ï¸ Audio Isolation pas geÃ§ildi.")
        except Exception as _:
            print("[/stt] âš ï¸ Audio Isolation baÅŸarÄ±sÄ±z, orijinal ses kullanÄ±lacak.")

        print("[/stt] ğŸ§¬ Base64 ses verisi decode ediliyor...")
        audio_bytes = base64.b64decode(base64_audio)
        print(f"[/stt] âœ… Decode baÅŸarÄ±lÄ±. Boyut: {len(audio_bytes)} byte")

        # OpenAI Whisper-1 transkripsiyon
        bio = io.BytesIO(audio_bytes)
        bio.name = "audio.m4a"  # dosya adÄ± gerekli
        transcript = client.audio.transcriptions.create(
            model="whisper-1",
            file=bio,
            # dil tahmini gÃ¼zel Ã§alÄ±ÅŸÄ±yor; gerekirse language="tr" verilebilir
        )
        text = transcript.text or ""
        print("[/stt] âœ… Ã‡Ã¶zÃ¼mleme baÅŸarÄ±lÄ±. Metin:", text[:120])
        return {"text": text}

    except Exception as e:
        print("[/stt] â—ï¸Hata:", str(e))
        raise HTTPException(status_code=500, detail=str(e))
